{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "import numpy as np\n",
        "import os\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "print(\"--- Starting Project Evaluation ---\")\n",
        "\n",
        "# Step 1: Data Loading\n",
        "file_path = '/content/drive/MyDrive/Datasets/city_day.csv'\n",
        "stations_file_path = '/content/drive/MyDrive/Datasets/stations.csv'\n",
        "\n",
        "try:\n",
        "    airpollution_df = pd.read_csv(file_path)\n",
        "    stations_data = pd.read_csv(stations_file_path)\n",
        "    print(\"1. Data loaded successfully.\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: {e}. Please check the file paths.\")\n",
        "    exit()\n",
        "\n",
        "# Step 2: Data Preprocessing and Feature Engineering\n",
        "print(\"2. Preprocessing and feature engineering in progress...\")\n",
        "\n",
        "# Merge with stations data to add more features\n",
        "airpollution_processed = pd.merge(airpollution_df, stations_data, on='City', how='left')\n",
        "\n",
        "# Convert 'Datetime' column to datetime and set it as the index\n",
        "airpollution_processed['Datetime'] = pd.to_datetime(airpollution_processed['Datetime'])\n",
        "airpollution_processed.set_index('Datetime', inplace=True)\n",
        "\n",
        "# Handle missing values using median for numerical columns\n",
        "for col in airpollution_processed.columns:\n",
        "    if airpollution_processed[col].dtype in ['float64', 'int64']:\n",
        "        median_val = airpollution_processed[col].median()\n",
        "        airpollution_processed[col].fillna(median_val, inplace=True)\n",
        "\n",
        "# Drop original categorical and non-feature columns BEFORE one-hot encoding City\n",
        "cols_to_drop_before_encoding = ['AQI_Bucket', 'Station', 'State', 'Location']\n",
        "existing_cols_to_drop_before_encoding = [col for col in cols_to_drop_before_encoding if col in airpollution_processed.columns]\n",
        "airpollution_processed.drop(existing_cols_to_drop_before_encoding, axis=1, inplace=True)\n",
        "\n",
        "# One-hot encode the 'City' column to handle categorical data\n",
        "if 'City' in airpollution_processed.columns:\n",
        "    city_dummies = pd.get_dummies(airpollution_processed['City'], prefix='city', dtype=int)\n",
        "    airpollution_processed = pd.concat([airpollution_processed, city_dummies], axis=1)\n",
        "    airpollution_processed.drop('City', axis=1, inplace=True)\n",
        "\n",
        "# Create new time-based features from the index\n",
        "airpollution_processed['month'] = airpollution_processed.index.month\n",
        "airpollution_processed['year'] = airpollution_processed.index.year\n",
        "airpollution_processed['day_of_week'] = airpollution_processed.index.dayofweek\n",
        "if 'AQI' in airpollution_processed.columns:\n",
        "    airpollution_processed['AQI_rolling_avg'] = airpollution_processed['AQI'].rolling(window=3, min_periods=1).mean()\n",
        "\n",
        "# Create Lag and Rolling features\n",
        "lag_cols = ['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3', 'Benzene', 'Toluene', 'Xylene', 'AQI']\n",
        "lag_steps = [1, 2, 7]\n",
        "for col in lag_cols:\n",
        "    if col in airpollution_processed.columns:\n",
        "        for step in lag_steps:\n",
        "            airpollution_processed[f'{col}_lag{step}'] = airpollution_processed[col].shift(step)\n",
        "\n",
        "rolling_cols = ['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3', 'Benzene', 'Toluene', 'Xylene', 'AQI']\n",
        "window_sizes = [3, 7, 30]\n",
        "for col in rolling_cols:\n",
        "    if col in airpollution_processed.columns:\n",
        "        for window in window_sizes:\n",
        "            airpollution_processed[f'{col}_rolling_mean_{window}d'] = airpollution_processed[col].rolling(window=window, min_periods=1).mean()\n",
        "            airpollution_processed[f'{col}_rolling_std_{window}d'] = airpollution_processed[col].rolling(window=window, min_periods=1).std()\n",
        "\n",
        "# Handle missing values introduced by lagging and rolling calculations\n",
        "for col in airpollution_processed.columns:\n",
        "    if '_lag' in col or '_rolling_' in col:\n",
        "        airpollution_processed[col].fillna(airpollution_processed[col].mean(), inplace=True)\n",
        "\n",
        "# Define X (features) and y (target)\n",
        "X = airpollution_processed.select_dtypes(include=np.number).drop('AQI', axis=1, errors='ignore')\n",
        "y = airpollution_processed['AQI']\n",
        "\n",
        "# Drop rows with any remaining NaN values\n",
        "combined = pd.concat([X, y], axis=1).dropna()\n",
        "X = combined.drop('AQI', axis=1)\n",
        "y = combined['AQI']\n",
        "\n",
        "# Save the feature list for the frontend\n",
        "joblib.dump(X.columns.tolist(), 'model_features.pkl')\n",
        "print(\"Features saved successfully as model_features.pkl\")\n",
        "\n",
        "# Step 3: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Train the XGBoost Model\n",
        "print(\"\\n--- Training XGBoost Model with New Features ---\")\n",
        "\n",
        "# Best parameters for tuning of XGBoost\n",
        "best_xgb_params = {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 300, 'subsample': 0.7}\n",
        "\n",
        "retrained_xgb_model = xgb.XGBRegressor(**best_xgb_params, random_state=42)\n",
        "retrained_xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Model Evaluation\n",
        "tuned_xgb_predictions_new_features = retrained_xgb_model.predict(X_test)\n",
        "tuned_xgb_r2_new_features = r2_score(y_test, tuned_xgb_predictions_new_features)\n",
        "tuned_xgb_mae_new_features = mean_absolute_error(y_test, tuned_xgb_predictions_new_features)\n",
        "\n",
        "# Output the results\n",
        "print(f\"XGBoost Model Mean Absolute Error (MAE): {tuned_xgb_mae_new_features}\")\n",
        "print(f\"XGBoost R-squared Score (R2): {tuned_xgb_r2_new_features}\")\n",
        "\n",
        "# Step 6: Save the final trained model\n",
        "joblib.dump(retrained_xgb_model, 'air_pollution_xgb_model.pkl')\n",
        "print(\"\\nModel saved successfully as as air_pollution_xgb_model.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQ8OfaFQ_EYd",
        "outputId": "298c5d99-e47a-49ab-aedd-cb88296600b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Project Evaluation ---\n",
            "1. Data loaded successfully.\n",
            "2. Preprocessing and feature engineering in progress...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2318037539.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  airpollution_processed[col].fillna(median_val, inplace=True)\n",
            "/tmp/ipython-input-2318037539.py:71: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  airpollution_processed[f'{col}_rolling_std_{window}d'] = airpollution_processed[col].rolling(window=window, min_periods=1).std()\n",
            "/tmp/ipython-input-2318037539.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  airpollution_processed[f'{col}_rolling_mean_{window}d'] = airpollution_processed[col].rolling(window=window, min_periods=1).mean()\n",
            "/tmp/ipython-input-2318037539.py:71: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  airpollution_processed[f'{col}_rolling_std_{window}d'] = airpollution_processed[col].rolling(window=window, min_periods=1).std()\n",
            "/tmp/ipython-input-2318037539.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  airpollution_processed[f'{col}_rolling_mean_{window}d'] = airpollution_processed[col].rolling(window=window, min_periods=1).mean()\n",
            "/tmp/ipython-input-2318037539.py:71: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  airpollution_processed[f'{col}_rolling_std_{window}d'] = airpollution_processed[col].rolling(window=window, min_periods=1).std()\n",
            "/tmp/ipython-input-2318037539.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  airpollution_processed[f'{col}_rolling_mean_{window}d'] = airpollution_processed[col].rolling(window=window, min_periods=1).mean()\n",
            "/tmp/ipython-input-2318037539.py:71: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  airpollution_processed[f'{col}_rolling_std_{window}d'] = airpollution_processed[col].rolling(window=window, min_periods=1).std()\n",
            "/tmp/ipython-input-2318037539.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  airpollution_processed[f'{col}_rolling_mean_{window}d'] = airpollution_processed[col].rolling(window=window, min_periods=1).mean()\n",
            "/tmp/ipython-input-2318037539.py:71: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  airpollution_processed[f'{col}_rolling_std_{window}d'] = airpollution_processed[col].rolling(window=window, min_periods=1).std()\n",
            "/tmp/ipython-input-2318037539.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  airpollution_processed[f'{col}_rolling_mean_{window}d'] = airpollution_processed[col].rolling(window=window, min_periods=1).mean()\n",
            "/tmp/ipython-input-2318037539.py:71: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  airpollution_processed[f'{col}_rolling_std_{window}d'] = airpollution_processed[col].rolling(window=window, min_periods=1).std()\n",
            "/tmp/ipython-input-2318037539.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  airpollution_processed[f'{col}_rolling_mean_{window}d'] = airpollution_processed[col].rolling(window=window, min_periods=1).mean()\n",
            "/tmp/ipython-input-2318037539.py:71: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  airpollution_processed[f'{col}_rolling_std_{window}d'] = airpollution_processed[col].rolling(window=window, min_periods=1).std()\n",
            "/tmp/ipython-input-2318037539.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  airpollution_processed[f'{col}_rolling_mean_{window}d'] = airpollution_processed[col].rolling(window=window, min_periods=1).mean()\n",
            "/tmp/ipython-input-2318037539.py:71: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  airpollution_processed[f'{col}_rolling_std_{window}d'] = airpollution_processed[col].rolling(window=window, min_periods=1).std()\n",
            "/tmp/ipython-input-2318037539.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  airpollution_processed[f'{col}_rolling_mean_{window}d'] = airpollution_processed[col].rolling(window=window, min_periods=1).mean()\n",
            "/tmp/ipython-input-2318037539.py:71: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  airpollution_processed[f'{col}_rolling_std_{window}d'] = airpollution_processed[col].rolling(window=window, min_periods=1).std()\n",
            "/tmp/ipython-input-2318037539.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  airpollution_processed[f'{col}_rolling_mean_{window}d'] = airpollution_processed[col].rolling(window=window, min_periods=1).mean()\n",
            "/tmp/ipython-input-2318037539.py:71: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  airpollution_processed[f'{col}_rolling_std_{window}d'] = airpollution_processed[col].rolling(window=window, min_periods=1).std()\n",
            "/tmp/ipython-input-2318037539.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  airpollution_processed[f'{col}_rolling_mean_{window}d'] = airpollution_processed[col].rolling(window=window, min_periods=1).mean()\n",
            "/tmp/ipython-input-2318037539.py:71: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  airpollution_processed[f'{col}_rolling_std_{window}d'] = airpollution_processed[col].rolling(window=window, min_periods=1).std()\n",
            "/tmp/ipython-input-2318037539.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  airpollution_processed[f'{col}_rolling_mean_{window}d'] = airpollution_processed[col].rolling(window=window, min_periods=1).mean()\n",
            "/tmp/ipython-input-2318037539.py:71: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  airpollution_processed[f'{col}_rolling_std_{window}d'] = airpollution_processed[col].rolling(window=window, min_periods=1).std()\n",
            "/tmp/ipython-input-2318037539.py:76: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  airpollution_processed[col].fillna(airpollution_processed[col].mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features saved successfully as model_features.pkl\n",
            "\n",
            "--- Training XGBoost Model with New Features ---\n",
            "XGBoost Model Mean Absolute Error (MAE): 4.1990624177579905\n",
            "XGBoost R-squared Score (R2): 0.998366390470257\n",
            "\n",
            "Model saved successfully as as air_pollution_xgb_model.pkl\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}